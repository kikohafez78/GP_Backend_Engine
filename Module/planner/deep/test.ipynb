{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "# import evaluate  # Bleu\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration, T5TokenizerFast\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "TOKENIZER = T5TokenizerFast.from_pretrained(\"t5-base\")\n",
    "MODEL = T5ForConditionalGeneration.from_pretrained(\"t5-base\", return_dict=True).to(DEVICE)\n",
    "OPTIMIZER = Adam(MODEL.parameters(), lr=0.00001)\n",
    "Q_LEN = 256   # Question Length\n",
    "T_LEN = 32    # Target Length\n",
    "BATCH_SIZE = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/SQUAD.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    articles = []\n",
    "    \n",
    "    for article in data[\"data\"]:\n",
    "        for paragraph in article[\"paragraphs\"]:\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                question = qa[\"question\"]\n",
    "\n",
    "                if not qa[\"is_impossible\"]:\n",
    "                  answer = qa[\"answers\"][0][\"text\"]\n",
    "                \n",
    "                inputs = {\"context\": paragraph[\"context\"], \"question\": question, \"answer\": answer}\n",
    "\n",
    "            \n",
    "                articles.append(inputs)\n",
    "\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data(data)\n",
    "\n",
    "# Create a Dataframe\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QA_Dataset(Dataset):\n",
    "    def __init__(self, tokenizer, dataframe, q_len, t_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.q_len = q_len\n",
    "        self.t_len = t_len\n",
    "        self.data = dataframe\n",
    "        self.questions = self.data[\"question\"]\n",
    "        self.context = self.data[\"context\"]\n",
    "        self.answer = self.data['answer']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions[idx]\n",
    "        context = self.context[idx]\n",
    "        answer = self.answer[idx]\n",
    "        \n",
    "        question_tokenized = self.tokenizer(question, context, max_length=self.q_len, padding=\"max_length\",\n",
    "                                                    truncation=True, pad_to_max_length=True, add_special_tokens=True)\n",
    "        answer_tokenized = self.tokenizer(answer, max_length=self.t_len, padding=\"max_length\", \n",
    "                                          truncation=True, pad_to_max_length=True, add_special_tokens=True)\n",
    "        \n",
    "        labels = torch.tensor(answer_tokenized[\"input_ids\"], dtype=torch.long)\n",
    "        labels[labels == 0] = -100\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(question_tokenized[\"input_ids\"], dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(question_tokenized[\"attention_mask\"], dtype=torch.long),\n",
    "            \"labels\": labels,\n",
    "            \"decoder_attention_mask\": torch.tensor(answer_tokenized[\"attention_mask\"], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_sampler = RandomSampler(train_data.index)\n",
    "val_sampler = RandomSampler(val_data.index)\n",
    "\n",
    "qa_dataset = QA_Dataset(TOKENIZER, data, Q_LEN, T_LEN)\n",
    "\n",
    "train_loader = DataLoader(qa_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "val_loader = DataLoader(qa_dataset, batch_size=BATCH_SIZE, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches:   1%|‚ñè         | 369/26064 [22:30<26:07:13,  3.66s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     23\u001b[0m     OPTIMIZER\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 24\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     25\u001b[0m     train_batch_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#Evaluation\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = 0\n",
    "val_loss = 0\n",
    "train_batch_count = 0\n",
    "val_batch_count = 0\n",
    "\n",
    "for epoch in range(2):\n",
    "    MODEL.train()\n",
    "    for batch in tqdm(train_loader, desc=\"Training batches\"):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE)\n",
    "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n",
    "\n",
    "        outputs = MODEL(\n",
    "                          input_ids=input_ids,\n",
    "                          attention_mask=attention_mask,\n",
    "                          labels=labels,\n",
    "                          decoder_attention_mask=decoder_attention_mask\n",
    "                        )\n",
    "\n",
    "        OPTIMIZER.zero_grad()\n",
    "        outputs.loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "        train_loss += outputs.loss.item()\n",
    "        train_batch_count += 1\n",
    "    \n",
    "    #Evaluation\n",
    "    MODEL.eval()\n",
    "    for batch in tqdm(val_loader, desc=\"Validation batches\"):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE)\n",
    "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n",
    "\n",
    "        outputs = MODEL(\n",
    "                          input_ids=input_ids,\n",
    "                          attention_mask=attention_mask,\n",
    "                          labels=labels,\n",
    "                          decoder_attention_mask=decoder_attention_mask\n",
    "                        )\n",
    "\n",
    "        OPTIMIZER.zero_grad()\n",
    "        outputs.loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "        val_loss += outputs.loss.item()\n",
    "        val_batch_count += 1\n",
    "        \n",
    "    print(f\"{epoch+1}/{2} -> Train loss: {train_loss / train_batch_count}\\tValidation loss: {val_loss/val_batch_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL.save_pretrained(\"qa_model\")\n",
    "TOKENIZER.save_pretrained(\"qa_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_answer(context, question, ref_answer=None):\n",
    "    inputs = TOKENIZER(question, context, max_length=Q_LEN, padding=\"max_length\", truncation=True, add_special_tokens=True)\n",
    "    \n",
    "    input_ids = torch.tensor(inputs[\"input_ids\"], dtype=torch.long).to(DEVICE).unsqueeze(0)\n",
    "    attention_mask = torch.tensor(inputs[\"attention_mask\"], dtype=torch.long).to(DEVICE).unsqueeze(0)\n",
    "\n",
    "    outputs = MODEL.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
    "  \n",
    "    predicted_answer = TOKENIZER.decode(outputs.flatten(), skip_special_tokens=True)\n",
    "    \n",
    "    if ref_answer:\n",
    "        # Load the Bleu metric\n",
    "        bleu = evaluate.load(\"google_bleu\")\n",
    "        score = bleu.compute(predictions=[predicted_answer], \n",
    "                            references=[ref_answer])\n",
    "    \n",
    "        print(\"Context: \\n\", context)\n",
    "        print(\"\\n\")\n",
    "        print(\"Question: \\n\", question)\n",
    "        return {\n",
    "            \"Reference Answer: \": ref_answer, \n",
    "            \"Predicted Answer: \": predicted_answer, \n",
    "            \"BLEU Score: \": score\n",
    "        }\n",
    "    else:\n",
    "        return predicted_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[': https://github.com/LexzLts/seq2seq.js\\n\\n\\n', ', see https://virtualjournals.nucleotide.org/~jwhilliam/']\n",
      "outdir:bloom‚Äîtest step:22 episode:0 R:0\n",
      "statistics:[('average_value', -1.4778271), ('average_entropy', 4.585436), ('average_value_loss', 0.7387949171289802), ('average_policy_loss', -0.0011688995361328126), ('n_updates', 110), ('explained_variance', 0.015487562513581077)]\n",
      "evaluation episode 0 length:22 R:0\n",
      "The best score is updated -3.4028235e+38 -> 0.0\n",
      "Saved the agent to bloom‚Äîtest\\best\n",
      "outdir:bloom‚Äîtest step:44 episode:1 R:0\n",
      "statistics:[('average_value', -1.5638729), ('average_entropy', 4.515419), ('average_value_loss', 4.631349843852222), ('average_policy_loss', -0.000910552740097046), ('n_updates', 220), ('explained_variance', -81.11072747373254)]\n",
      "evaluation episode 0 length:22 R:0\n",
      "outdir:bloom‚Äîtest step:66 episode:2 R:0\n",
      "statistics:[('average_value', -1.5584759), ('average_entropy', 4.5343103), ('average_value_loss', 0.8725760350003838), ('average_policy_loss', -0.0012129700183868407), ('n_updates', 330), ('explained_variance', 0.7402729556137404)]\n",
      "evaluation episode 0 length:22 R:0\n",
      "outdir:bloom‚Äîtest step:88 episode:3 R:0\n",
      "statistics:[('average_value', -1.5202248), ('average_entropy', 4.6841063), ('average_value_loss', 0.442728675622493), ('average_policy_loss', -0.001291179060935974), ('n_updates', 440), ('explained_variance', -1.5879948615611048)]\n",
      "evaluation episode 0 length:22 R:0\n",
      "outdir:bloom‚Äîtest step:100 episode:4 R:0\n",
      "statistics:[('average_value', -1.5305047), ('average_entropy', 4.542726), ('average_value_loss', 1.1556901606731116), ('average_policy_loss', -0.0009512877464294433), ('n_updates', 500), ('explained_variance', -0.47420700015903616)]\n",
      "evaluation episode 0 length:22 R:0\n",
      "Saved the agent to bloom‚Äîtest\\100_finish\n",
      "[', so the learning curve for those protocols needs understanding to match them to observations. If you are interested', '. All increase in vir75H sex ratio and the anionic status of the man must be learned']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import logging\n",
    "import sys\n",
    "from qt5.training_rl import train_agent_with_evaluation\n",
    "from qt5.environment import TextRLEnv\n",
    "from qt5.actor import TextRLActor\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout, format='')\n",
    "\n",
    "checkpoint = \"gpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, torch_dtype=\"auto\", device_map=\"auto\")\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "class MyRLEnv(TextRLEnv):\n",
    "    def get_reward(self, input_item, predicted_list, finish):  # predicted will be the list of predicted token\n",
    "        reward = [0]\n",
    "        if finish:\n",
    "            reward = [1]  # calculate reward score base on predicted_list\n",
    "        return reward\n",
    "\n",
    "\n",
    "observaton_list = [{\"input\":\"explain how attention work in seq2seq model\"}]\n",
    "env = TextRLEnv(model, tokenizer, observation_input=observaton_list, max_length=20, compare_sample=2)\n",
    "actor = TextRLActor(env, model, tokenizer,\n",
    "                    act_deterministically=False,\n",
    "                    temperature=1.0,\n",
    "                    top_k=0,\n",
    "                    top_p=1.0)\n",
    "agent = actor.agent_ppo(update_interval=2, minibatch_size=2, epochs=10)\n",
    "print(actor.predict(observaton_list[0]))\n",
    "\n",
    "train_agent_with_evaluation(\n",
    "    agent,\n",
    "    env,\n",
    "    steps=100,\n",
    "    eval_n_steps=None,\n",
    "    eval_n_episodes=1,\n",
    "    eval_interval=2,\n",
    "    outdir='bloom‚Äîtest',\n",
    ")\n",
    "\n",
    "print(actor.predict(observaton_list[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
