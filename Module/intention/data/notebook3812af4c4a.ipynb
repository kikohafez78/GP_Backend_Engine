{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T22:36:16.974643Z","iopub.status.busy":"2024-05-20T22:36:16.974283Z","iopub.status.idle":"2024-05-20T22:36:34.252034Z","shell.execute_reply":"2024-05-20T22:36:34.251228Z","shell.execute_reply.started":"2024-05-20T22:36:16.974615Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\conda\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n","  torch.utils._pytree._register_pytree_node(\n","d:\\conda\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n","  torch.utils._pytree._register_pytree_node(\n"]}],"source":["# from bert_model_implementation_torch.model import BertModel\n","# from bert_model_implementation_torch.tokenization import  _is_control,_is_whitespace,_is_punctuation\n","from transformers import BertTokenizer, BertModel\n","from sklearn.model_selection import train_test_split\n","import torch \n","import torch.nn as nn\n","import numpy as np\n","import pandas as pd\n","import sys\n","from tqdm import tqdm\n","from keras.src.utils import to_categorical\n","from torch.utils.data import DataLoader\n","import shutil\n","import re"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T22:36:35.248968Z","iopub.status.busy":"2024-05-20T22:36:35.248637Z","iopub.status.idle":"2024-05-20T22:36:35.254010Z","shell.execute_reply":"2024-05-20T22:36:35.252776Z","shell.execute_reply.started":"2024-05-20T22:36:35.248936Z"},"trusted":true},"outputs":[],"source":["def mask_tokens(text: str):\n","    return re.sub(r'<[^>]+>', '[MASK]', text)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T22:36:35.256601Z","iopub.status.busy":"2024-05-20T22:36:35.256288Z","iopub.status.idle":"2024-05-20T22:36:36.217771Z","shell.execute_reply":"2024-05-20T22:36:36.216446Z","shell.execute_reply.started":"2024-05-20T22:36:35.256572Z"},"trusted":true},"outputs":[],"source":["!mkdir ckpts experiments"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T22:36:36.219536Z","iopub.status.busy":"2024-05-20T22:36:36.219233Z","iopub.status.idle":"2024-05-20T22:36:36.351191Z","shell.execute_reply":"2024-05-20T22:36:36.350400Z","shell.execute_reply.started":"2024-05-20T22:36:36.219506Z"},"trusted":true},"outputs":[],"source":["data = pd.read_csv(\"./balanced_data.csv\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T22:36:38.565019Z","iopub.status.busy":"2024-05-20T22:36:38.564322Z","iopub.status.idle":"2024-05-20T22:36:38.584809Z","shell.execute_reply":"2024-05-20T22:36:38.583946Z","shell.execute_reply.started":"2024-05-20T22:36:38.564991Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt</th>\n","      <th>intent</th>\n","      <th>classes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Create a spider chart comparing employee perfo...</td>\n","      <td>Set trend line</td>\n","      <td>charts</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>I need to divide the text in cell &lt;Cell&gt; by th...</td>\n","      <td>Split text to columns</td>\n","      <td>entry and manipulation</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>How do you hide formulas on Expenses</td>\n","      <td>Display formulas</td>\n","      <td>formatting</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Relative to customer, Adjust Pivot Table Sourc...</td>\n","      <td>Change Pivot Table Source Data</td>\n","      <td>pivot tables</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Please strip away the formatting from these ce...</td>\n","      <td>Delete format</td>\n","      <td>formatting</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              prompt  \\\n","0  Create a spider chart comparing employee perfo...   \n","1  I need to divide the text in cell <Cell> by th...   \n","2               How do you hide formulas on Expenses   \n","3  Relative to customer, Adjust Pivot Table Sourc...   \n","4  Please strip away the formatting from these ce...   \n","\n","                           intent                 classes  \n","0                  Set trend line                  charts  \n","1           Split text to columns  entry and manipulation  \n","2                Display formulas              formatting  \n","3  Change Pivot Table Source Data            pivot tables  \n","4                   Delete format              formatting  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T22:40:35.856003Z","iopub.status.busy":"2024-05-20T22:40:35.855282Z","iopub.status.idle":"2024-05-20T22:40:35.861355Z","shell.execute_reply":"2024-05-20T22:40:35.860334Z","shell.execute_reply.started":"2024-05-20T22:40:35.855973Z"},"trusted":true},"outputs":[],"source":["import os\n","wd = os.getcwd()\n","config = {\n","    'max_len': 256,\n","    'batch_size': 8,\n","    'epochs': 10,\n","    'lr':1e-07,\n","    'out_first_layer': 768,\n","    'dropout_rate': 0.1,\n","    'model_dir':'bert-base-cased',\n","    'ckpt_path': os.path.join(wd, 'kaggle\\\\working\\\\ckpts'),\n","    'ckpt_model_path': os.path.join(wd, 'kaggle\\\\working\\\\experiments')\n","}"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T22:40:39.998784Z","iopub.status.busy":"2024-05-20T22:40:39.998045Z","iopub.status.idle":"2024-05-20T22:40:40.006000Z","shell.execute_reply":"2024-05-20T22:40:40.005122Z","shell.execute_reply.started":"2024-05-20T22:40:39.998741Z"},"trusted":true},"outputs":[],"source":["intent_list = data.intent.unique().tolist()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T22:40:41.373584Z","iopub.status.busy":"2024-05-20T22:40:41.373238Z","iopub.status.idle":"2024-05-20T22:40:41.382818Z","shell.execute_reply":"2024-05-20T22:40:41.381969Z","shell.execute_reply.started":"2024-05-20T22:40:41.373559Z"},"trusted":true},"outputs":[],"source":["class IntentDataset:\n","    def __init__(self, df: pd.DataFrame, tokenizer: BertTokenizer, max_len: int):\n","        self.df = df\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        self.classes = df['intent'].unique().tolist()\n","        self.y = df['intent']\n","        self.x = df['prompt']\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, index):\n","        title = str(self.x[index])\n","        title = ''.join(title.split())\n","        title = mask_tokens(title)  # Assuming mask_tokens is a function defined elsewhere\n","        inputs = self.tokenizer.encode_plus(\n","            title,\n","            None,\n","            add_special_tokens=True,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","            return_token_type_ids=True,\n","            padding='max_length',\n","            max_length=self.max_len,\n","            truncation=True\n","        )\n","        target = self.classes.index(self.y[index])  # Get the class index\n","        return {\n","            'input_ids': inputs[\"input_ids\"].flatten(),\n","            'token_type_ids': inputs['token_type_ids'].flatten(),\n","            'attention_mask': inputs['attention_mask'].flatten(),\n","            'targets': torch.tensor(target, dtype=torch.long)  # Directly use class index\n","        }"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T22:40:44.672785Z","iopub.status.busy":"2024-05-20T22:40:44.671948Z","iopub.status.idle":"2024-05-20T22:40:44.685419Z","shell.execute_reply":"2024-05-20T22:40:44.684400Z","shell.execute_reply.started":"2024-05-20T22:40:44.672753Z"},"trusted":true},"outputs":[],"source":["train = data.sample(frac=0.9, random_state=200).reset_index(drop=True)\n","val = data.drop(train.index).reset_index(drop=True)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T22:48:30.729559Z","iopub.status.busy":"2024-05-20T22:48:30.728684Z"},"trusted":true},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained(config[\"model_dir\"])\n","train_dataset = IntentDataset(train, tokenizer, config[\"max_len\"])\n","val_dataset = IntentDataset(val, tokenizer, config[\"max_len\"])"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.status.busy":"2024-05-20T22:24:20.188073Z","iopub.status.idle":"2024-05-20T22:24:20.188580Z","shell.execute_reply":"2024-05-20T22:24:20.188331Z","shell.execute_reply.started":"2024-05-20T22:24:20.188311Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'input_ids': tensor([ 101,  100,  103, 1105,  102,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0]),\n"," 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n"," 'attention_mask': tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n"," 'targets': tensor(10)}"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset.__getitem__(10)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.status.busy":"2024-05-20T22:24:20.190037Z","iopub.status.idle":"2024-05-20T22:24:20.190551Z","shell.execute_reply":"2024-05-20T22:24:20.190290Z","shell.execute_reply.started":"2024-05-20T22:24:20.190270Z"},"trusted":true},"outputs":[],"source":["train_loader = DataLoader(\n","    train_dataset,\n","    shuffle = True,\n","    batch_size = config[\"batch_size\"],\n","    num_workers = 0\n","    )\n","\n","val_loader = DataLoader(\n","    val_dataset,\n","    shuffle = False,\n","    batch_size = config[\"batch_size\"],\n","    num_workers = 0\n","    )"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["tensor(10)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["train_loader.dataset[10]['targets']\n"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["256"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["len(train_loader.dataset[0]['input_ids'])\n"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","print(device)"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[],"source":["def load_ckpt(ckpt_path, model, optimizer):\n","    ckpt = torch.load(ckpt_path)\n","    model.load_state_dict(ckpt['state_dict'])\n","    optimizer.load_state_dict(ckpt['state_dict'])\n","    valid_loss_min = ckpt['valid_loss_min']\n","    return model, optimizer, ckpt['epoch'], valid_loss_min.item()"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[],"source":["def save_ckpt(state, is_best, ckpt_path, best_model_path):\n","    f_path= ckpt_path\n","    torch.save(state, f_path)\n","    if is_best:\n","        best_f_path = best_model_path\n","        shutil.copyfile(f_path, best_f_path)"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[],"source":["class intent_model(nn.Module):\n","    def __init__(self, config: dict, intent_labels: list[str], dropout: float = 0.1):\n","        super(intent_model,self).__init__()\n","        self.config = config\n","        self.intent_labels = intent_labels\n","        self.dropout_rate = dropout\n","        self.bert = BertModel.from_pretrained(self.config[\"model_dir\"])\n","        self.dropout = nn.Dropout(self.dropout_rate)\n","        self.layer_1 = nn.Linear(self.bert.config.hidden_size,self.config[\"out_first_layer\"])\n","        self.activation_1 = nn.ReLU()\n","        self.layer_2 = nn.Linear(self.config[\"out_first_layer\"], len(self.intent_labels))\n","        \n","    def forward(self, input_ids: torch.Tensor, token_type_ids: torch.Tensor, attention_mask: torch.Tensor):\n","        output = self.bert(input_ids, token_type_ids, attention_mask)\n","        output_dropout = self.dropout(output.pooler_output)\n","        out_layer_1 = self.layer_1(output_dropout)\n","        act_1 = self.activation_1(out_layer_1)\n","        out_layer_2 = self.layer_2(act_1)\n","        return out_layer_2\n","        "]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[],"source":["model = intent_model(config, intent_list, 0.1)\n","model.to(device)\n","def loss_fn(outputs, targets):\n","    targets = targets.float()\n","    return nn.CrossEntropyLoss()(outputs, targets)"]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[],"source":["loss_fn = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":23,"metadata":{"trusted":true},"outputs":[],"source":["\n","\n","optimizer = torch.optim.Adam(params = model.parameters(), lr = config[\"lr\"])"]},{"cell_type":"code","execution_count":24,"metadata":{"trusted":true},"outputs":[],"source":["# checkpoint = {\n","#     'epoch': 10 +1,\n","#     'valid_loss_min': 0,\n","#     'state_dict': model.state_dict(),\n","#     'optimizer': optimizer.state_dict()\n","# }\n","# save_ckpt(checkpoint, False, config[\"ckpt_path\"], config[\"ckpt_model_path\"])"]},{"cell_type":"code","execution_count":26,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  3%|â–Ž         | 121/3589 [07:18<3:29:19,  3.62s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[26], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m         save_ckpt(checkpoint, \u001b[38;5;28;01mFalse\u001b[39;00m, ckpt_path, best_model_path)  \u001b[38;5;66;03m# Assuming save_ckpt is defined elsewhere\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m---> 45\u001b[0m model \u001b[38;5;241m=\u001b[39m train(model, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m], train_loader, val_loader, optimizer, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mckpt_path\u001b[39m\u001b[38;5;124m\"\u001b[39m], config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mckpt_model_path\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n","Cell \u001b[1;32mIn[26], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, epochs, train_loader, val_loader, optimizer, ckpt_path, best_model_path)\u001b[0m\n\u001b[0;32m     16\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 19\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (batch_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m (loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m-\u001b[39m train_loss)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ended with train loss of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","def train(model, epochs, train_loader, val_loader, optimizer, ckpt_path, best_model_path):\n","    valid_loss_min = np.Inf\n","    for epoch in range(1, epochs + 1):\n","        train_loss = 0\n","        val_loss = 0\n","        model.train()\n","        for batch_index, batch in tqdm(enumerate(train_loader), total=len(train_loader)):\n","            input_ids = batch['input_ids'].to(device, dtype=torch.long)\n","            attention_mask = batch[\"attention_mask\"].to(device, dtype=torch.long)\n","            token_type_ids = batch[\"token_type_ids\"].to(device, dtype=torch.long)\n","            targets = batch[\"targets\"].to(device, dtype=torch.long)\n","            \n","            optimizer.zero_grad()\n","            outputs = model(input_ids, token_type_ids, attention_mask)\n","            loss = loss_fn(outputs, targets)\n","            loss.backward()\n","            optimizer.step()\n","            \n","            train_loss += (1 / (batch_index + 1)) * (loss.item() - train_loss)\n","        print(f\"Epoch {epoch} ended with train loss of {train_loss}\")\n","        \n","        model.eval()\n","        with torch.no_grad():\n","            for batch_index, batch in tqdm(enumerate(val_loader), total=len(val_loader)):\n","                input_ids = batch['input_ids'].to(device, dtype=torch.long)\n","                attention_mask = batch[\"attention_mask\"].to(device, dtype=torch.long)\n","                token_type_ids = batch[\"token_type_ids\"].to(device, dtype=torch.long)\n","                targets = batch[\"targets\"].to(device, dtype=torch.long)\n","                \n","                outputs = model(input_ids, token_type_ids, attention_mask)\n","                loss = loss_fn(outputs, targets)\n","                \n","                val_loss += (1 / (batch_index + 1)) * (loss.item() - val_loss)\n","        print(f\"Epoch {epoch} ended with val loss of {val_loss}\")\n","        \n","        checkpoint = {\n","            'epoch': epoch + 1,\n","            'valid_loss_min': val_loss,\n","            'state_dict': model.state_dict(),\n","            'optimizer': optimizer.state_dict()\n","        }\n","        save_ckpt(checkpoint, False, ckpt_path, best_model_path)  # Assuming save_ckpt is defined elsewhere\n","\n","    return model\n","model = train(model, config[\"epochs\"], train_loader, val_loader, optimizer, config[\"ckpt_path\"], config[\"ckpt_model_path\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import subprocess\n","from IPython.display import FileLink, display\n","import torch.nn.functional as F\n","def download_file(path, download_file_name):\n","    os.chdir('/kaggle/working/')\n","    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n","    command = f\"zip {zip_name} {path} -r\"\n","    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n","    if result.returncode != 0:\n","        print(\"Unable to run zip command!\")\n","        print(result.stderr)\n","        return\n","    display(FileLink(f'{download_file_name}.zip'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def predict_intent(model, text: str, tokenizer: BertTokenizer):\n","        # Tokenize input text\n","        text = mask_tokens(text)\n","        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n","        input_ids = inputs['input_ids']\n","        token_type_ids = inputs['token_type_ids']\n","        attention_mask = inputs['attention_mask']\n","        \n","        # Move tensors to the appropriate device\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        model.to(device)\n","        input_ids = input_ids.to(device)\n","        token_type_ids = token_type_ids.to(device)\n","        attention_mask = attention_mask.to(device)\n","        \n","        # Make predictions\n","        model.eval()  # Set the model to evaluation mode\n","        with torch.no_grad():\n","            logits = model(input_ids, token_type_ids, attention_mask)\n","        \n","        # Convert logits to probabilities\n","        probs = F.softmax(logits, dim=1)\n","        \n","        # Get the predicted label\n","        predicted_label_idx = torch.argmax(probs, dim=1).item()\n","        print(predicted_label_idx,torch.max(probs, dim=1))\n","        predicted_label = model.intent_labels[predicted_label_idx]\n","        \n","        return predicted_label, probs[0].cpu().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["predict_intent(model, \"sdavbasjdvasdkvbajsdjv sdcsdvsddsgsdfs\", tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["download_file(\"./\", \"ckpt\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5051334,"sourceId":8471291,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
