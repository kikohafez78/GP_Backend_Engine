{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "d:\\conda\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "05/18/2024 19:41:52 - INFO - numexpr.utils -   Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "05/18/2024 19:41:52 - INFO - numexpr.utils -   NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "# from bert_model_implementation_torch.model import BertModel\n",
    "from bert_model_implementation_torch.tokenization import  _is_control,_is_whitespace,_is_punctuation\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from keras.src.utils import to_categorical\n",
    "from torch.utils.data import DataLoader\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/Book1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>intent</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you update the sales figures in cells &lt;Cel...</td>\n",
       "      <td>Update cell range</td>\n",
       "      <td>entry and manipulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please modify the data in range &lt;Range&gt;</td>\n",
       "      <td>Update cell range</td>\n",
       "      <td>entry and manipulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I need to change the prices in cells &lt;Range&gt;</td>\n",
       "      <td>Update cell range</td>\n",
       "      <td>entry and manipulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Could you update the inventory levels from &lt;Ce...</td>\n",
       "      <td>Update cell range</td>\n",
       "      <td>entry and manipulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Please adjust the budget numbers in range &lt;Range&gt;</td>\n",
       "      <td>Update cell range</td>\n",
       "      <td>entry and manipulation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt             intent  \\\n",
       "0  Can you update the sales figures in cells <Cel...  Update cell range   \n",
       "1            Please modify the data in range <Range>  Update cell range   \n",
       "2       I need to change the prices in cells <Range>  Update cell range   \n",
       "3  Could you update the inventory levels from <Ce...  Update cell range   \n",
       "4  Please adjust the budget numbers in range <Range>  Update cell range   \n",
       "\n",
       "                  classes  \n",
       "0  entry and manipulation  \n",
       "1  entry and manipulation  \n",
       "2  entry and manipulation  \n",
       "3  entry and manipulation  \n",
       "4  entry and manipulation  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'max_len': 256,\n",
    "    'batch_size': 8,\n",
    "    'epochs': 10,\n",
    "    'lr':1e-05,\n",
    "    'out_first_layer': 768,\n",
    "    'dropout_rate': 0.1,\n",
    "    'model_dir':'bert-base-cased',\n",
    "    'ckpt_path': './ckpts',\n",
    "    'ckpt_model_path': './experiments'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_list = data.intent.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class intent_dataset:\n",
    "    def __init__(self, df: pd.DataFrame, tokenizer: BertTokenizer, max_len: int):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.classes = data.intent.unique().tolist()\n",
    "        self.y = df['intent']\n",
    "        self.x = df['prompt']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        title = str(self.x[index])\n",
    "        title= ''.join(title.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            title,\n",
    "            None,\n",
    "            add_special_tokens = True,\n",
    "            return_attention_mask = True,\n",
    "            return_tensors = 'pt',\n",
    "            return_token_type_ids = True,\n",
    "            padding = 'max_length',\n",
    "            max_length = self.max_len,\n",
    "            truncation = True\n",
    "        )\n",
    "        # print(self.classes.index(self.y[index]))\n",
    "        target = self.classes.index(self.y[index])  # Get the class index\n",
    "        target_tensor = torch.zeros(len(self.classes),dtype= torch.float32)  # Initialize target tensor with zeros\n",
    "        target_tensor[target] = 1  # Set the corresponding index to 1\n",
    "        return {\n",
    "            'input_ids': inputs[\"input_ids\"].flatten(),\n",
    "            'token_type_ids': inputs['token_type_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'targets': target_tensor\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.sample(frac=0.9, random_state=200).reset_index(drop=True)\n",
    "val = data.drop(train.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(config[\"model_dir\"])\n",
    "train_dataset = intent_dataset(train, tokenizer, config[\"max_len\"])\n",
    "val_dataset = intent_dataset(val, tokenizer, config[\"max_len\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle = True,\n",
    "    batch_size = config[\"batch_size\"],\n",
    "    num_workers = 0\n",
    "    )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    shuffle = False,\n",
    "    batch_size = config[\"batch_size\"],\n",
    "    num_workers = 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[10]['targets']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader.dataset[0]['input_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckpt(ckpt_path, model, optimizer):\n",
    "    ckpt = torch.load(ckpt_path)\n",
    "    # print(ckpt)\n",
    "    model.load_state_dict(ckpt['state_dict'])\n",
    "    # optimizer.load_state_dict(ckpt['state_dict'])\n",
    "    valid_loss_min = ckpt['valid_loss_min']\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ckpt(state, is_best, ckpt_path, best_model_path):\n",
    "    f_path= ckpt_path\n",
    "    torch.save(state, f_path)\n",
    "    if is_best:\n",
    "        best_f_path = best_model_path\n",
    "        shutil.copyfile(f_path, best_f_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class intent_model(nn.Module):\n",
    "    def __init__(self, config: dict, intent_labels: list[str], dropout: float = 0.1):\n",
    "        super(intent_model,self).__init__()\n",
    "        self.config = config\n",
    "        self.intent_labels = intent_labels\n",
    "        self.dropout_rate = dropout\n",
    "        self.bert = BertModel.from_pretrained(self.config[\"model_dir\"])\n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "        self.layer_1 = nn.Linear(self.bert.config.hidden_size,self.config[\"out_first_layer\"])\n",
    "        self.activation_1 = nn.ReLU()\n",
    "        self.layer_2 = nn.Linear(self.config[\"out_first_layer\"], len(self.intent_labels))\n",
    "        \n",
    "    def forward(self, input_ids: torch.Tensor, token_type_ids: torch.Tensor, attention_mask: torch.Tensor):\n",
    "        output = self.bert(input_ids, token_type_ids, attention_mask)\n",
    "        output_dropout = self.dropout(output.pooler_output)\n",
    "        out_layer_1 = self.layer_1(output_dropout)\n",
    "        act_1 = self.activation_1(out_layer_1)\n",
    "        out_layer_2 = self.layer_2(act_1)\n",
    "        return out_layer_2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/16/2024 01:11:17 - INFO - bert_model_implementation_torch.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased.tar.gz not found in cache, downloading to C:\\Users\\kikos\\AppData\\Local\\Temp\\tmpcjv867ym\n",
      "100%|██████████| 404400730/404400730 [07:17<00:00, 925346.54B/s] \n",
      "05/16/2024 01:18:36 - INFO - bert_model_implementation_torch.file_utils -   copying C:\\Users\\kikos\\AppData\\Local\\Temp\\tmpcjv867ym to cache at C:\\Users\\kikos\\.pytorch_pretrained_bert\\a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c\n",
      "05/16/2024 01:18:36 - INFO - bert_model_implementation_torch.file_utils -   creating metadata file for C:\\Users\\kikos\\.pytorch_pretrained_bert\\a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c\n",
      "05/16/2024 01:18:36 - INFO - bert_model_implementation_torch.file_utils -   removing temp file C:\\Users\\kikos\\AppData\\Local\\Temp\\tmpcjv867ym\n",
      "05/16/2024 01:18:36 - INFO - bert_model_implementation_torch.model -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased.tar.gz from cache at C:\\Users\\kikos\\.pytorch_pretrained_bert\\a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c\n",
      "05/16/2024 01:18:36 - INFO - bert_model_implementation_torch.model -   extracting archive file C:\\Users\\kikos\\.pytorch_pretrained_bert\\a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c to temp dir C:\\Users\\kikos\\AppData\\Local\\Temp\\tmp0roo9uvs\n",
      "05/16/2024 01:18:39 - INFO - bert_model_implementation_torch.model -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "intent_model(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (layer_1): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (activation_1): ReLU()\n",
       "  (layer_2): Linear(in_features=768, out_features=93, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = intent_model(config, intent_list, 0.1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    targets = targets.float()\n",
    "    return nn.BCEWithLogitsLoss()(outputs, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, train_loader, val_loader, optimizer, ckpt_path, best_model_path):\n",
    "    valid_loss_min = np.Inf\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "        model.train()\n",
    "        for batch_index, batch in tqdm(enumerate(train_loader)):\n",
    "            input_ids = batch['input_ids'].to(device, dtype= torch.long)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device, dtype= torch.long)\n",
    "            token_type_ids = batch[\"token_type_ids\"].to(device, dtype= torch.long)\n",
    "            targets = batch[\"targets\"].to(device, dtype= torch.long)\n",
    "            outputs = model(input_ids, token_type_ids, attention_mask)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += (1/(batch_index + 1)) * (loss.item() - train_loss)\n",
    "        print(f\"epoch {epoch} ended with train loss of {train_loss}\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_index, batch in tqdm(enumerate(val_loader)):\n",
    "                input_ids = batch['input_ids'].to(device, dtype= torch.long)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device, dtype= torch.long)\n",
    "                token_type_ids = batch[\"token_type_ids\"].to(device, dtype= torch.long)\n",
    "                targets = batch[\"targets\"].to(device, dtype= torch.long)\n",
    "                outputs = model(input_ids, token_type_ids, attention_mask)\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                valid_loss += (1/(batch_index + 1)) * (loss.item() - valid_loss)\n",
    "        print(f\"epoch {epoch} ended with train loss of {valid_loss}\")\n",
    "        checkpoint = {\n",
    "            'epoch': epoch +1,\n",
    "            'valid_loss_min': valid_loss,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "        save_ckpt(checkpoint, False, ckpt_path, best_model_path)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:02, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train \u001b[38;5;241m=\u001b[39m train(model, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m], train_loader, val_loader, optimizer, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mckpt_path\u001b[39m\u001b[38;5;124m\"\u001b[39m], config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mckpt_model_path\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[1;32mIn[41], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, epochs, train_loader, val_loader, optimizer, ckpt_path, best_model_path)\u001b[0m\n\u001b[0;32m     10\u001b[0m token_type_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m     11\u001b[0m targets \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m---> 12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_ids, token_type_ids, attention_mask)\n\u001b[0;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, targets)\n",
      "File \u001b[1;32md:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[35], line 14\u001b[0m, in \u001b[0;36mintent_model.forward\u001b[1;34m(self, input_ids, token_type_ids, attention_mask)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids: torch\u001b[38;5;241m.\u001b[39mTensor, token_type_ids: torch\u001b[38;5;241m.\u001b[39mTensor, attention_mask: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m---> 14\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert(input_ids, token_type_ids, attention_mask)\n\u001b[0;32m     15\u001b[0m     output_dropout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(output\u001b[38;5;241m.\u001b[39mpooler_output)\n\u001b[0;32m     16\u001b[0m     out_layer_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_1(output_dropout)\n",
      "File \u001b[1;32md:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\GP__KRYM\\clean_gp\\Module\\intention\\deep\\bert_model_implementation_torch\\model.py:455\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[0;32m    452\u001b[0m extended_attention_mask \u001b[38;5;241m=\u001b[39m extended_attention_mask\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;66;03m# fp16 compatibility\u001b[39;00m\n\u001b[0;32m    453\u001b[0m extended_attention_mask \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m extended_attention_mask) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10000.0\u001b[39m\n\u001b[1;32m--> 455\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids, token_type_ids)\n\u001b[0;32m    456\u001b[0m encoded_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(embedding_output,\n\u001b[0;32m    457\u001b[0m                               extended_attention_mask,\n\u001b[0;32m    458\u001b[0m                               output_all_encoded_layers\u001b[38;5;241m=\u001b[39moutput_all_encoded_layers)\n\u001b[0;32m    459\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoded_layers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32md:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\GP__KRYM\\clean_gp\\Module\\intention\\deep\\bert_model_implementation_torch\\model.py:141\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[1;34m(self, input_ids, token_type_ids)\u001b[0m\n\u001b[0;32m    138\u001b[0m token_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[0;32m    140\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m words_embeddings \u001b[38;5;241m+\u001b[39m position_embeddings \u001b[38;5;241m+\u001b[39m token_type_embeddings\n\u001b[1;32m--> 141\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(embeddings)\n\u001b[0;32m    142\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(embeddings)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "File \u001b[1;32md:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\GP__KRYM\\clean_gp\\Module\\intention\\deep\\bert_model_implementation_torch\\model.py:111\u001b[0m, in \u001b[0;36mBertLayerNorm.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 111\u001b[0m     u \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    112\u001b[0m     s \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m-\u001b[39m u)\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    113\u001b[0m     x \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m-\u001b[39m u) \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(s \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariance_epsilon)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "train = train(model, config[\"epochs\"], train_loader, val_loader, optimizer, config[\"ckpt_path\"], config[\"ckpt_model_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'max_len': 256,\n",
    "    'batch_size': 8,\n",
    "    'epochs': 10,\n",
    "    'lr':1e-05,\n",
    "    'out_first_layer': 768,\n",
    "    'dropout_rate': 0.1,\n",
    "    'model_dir':'bert-base-cased',\n",
    "    'ckpt_path': './ckpts',\n",
    "    'ckpt_model_path': './experiments'\n",
    "}\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class intent_model(nn.Module):\n",
    "    def __init__(self, config: dict, intent_labels: list[str], dropout: float = 0.1):\n",
    "        super(intent_model, self).__init__()\n",
    "        self.config = config\n",
    "        self.intent_labels = intent_labels\n",
    "        self.dropout_rate = dropout\n",
    "        self.bert = BertModel.from_pretrained(self.config[\"model_dir\"])\n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "        self.layer_1 = nn.Linear(self.bert.config.hidden_size, self.config[\"out_first_layer\"])\n",
    "        self.activation_1 = nn.ReLU()\n",
    "        self.layer_2 = nn.Linear(self.config[\"out_first_layer\"], len(self.intent_labels))\n",
    "        \n",
    "    def forward(self, input_ids: torch.Tensor, token_type_ids: torch.Tensor, attention_mask: torch.Tensor):\n",
    "        output = self.bert(input_ids, token_type_ids, attention_mask)\n",
    "        output_dropout = self.dropout(output.pooler_output)\n",
    "        out_layer_1 = self.layer_1(output_dropout)\n",
    "        act_1 = self.activation_1(out_layer_1)\n",
    "        out_layer_2 = self.layer_2(act_1)\n",
    "        return out_layer_2\n",
    "    \n",
    "    def predict_intent(self, text: str, tokenizer: BertTokenizer):\n",
    "        # Tokenize input text\n",
    "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "        input_ids = inputs['input_ids']\n",
    "        token_type_ids = inputs['token_type_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        \n",
    "        # Move tensors to the appropriate device\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "        input_ids = input_ids.to(device)\n",
    "        token_type_ids = token_type_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        \n",
    "        # Make predictions\n",
    "        self.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            logits = self(input_ids, token_type_ids, attention_mask)\n",
    "        \n",
    "        # Convert logits to probabilities\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        \n",
    "        # Get the predicted label\n",
    "        predicted_label_idx = torch.argmax(probs, dim=1).item()\n",
    "        print(predicted_label_idx)\n",
    "        predicted_label = self.intent_labels[predicted_label_idx]\n",
    "        \n",
    "        return predicted_label, probs[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(config[\"model_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = config[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intent_model(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (layer_1): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (activation_1): ReLU()\n",
       "  (layer_2): Linear(in_features=768, out_features=93, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = intent_model(config, intent_list, 0.1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 30522. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.resize_token_embeddings(30522)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_ckpt(\"./ckpts/ckpt\", model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Delete hyperlink',\n",
       " array([0.01483624, 0.00962736, 0.01309677, 0.01109273, 0.01267296,\n",
       "        0.01391257, 0.01042866, 0.01172547, 0.01188861, 0.01360726,\n",
       "        0.01299947, 0.01062253, 0.01138435, 0.01929716, 0.01973281,\n",
       "        0.00815214, 0.01179272, 0.01155274, 0.01214933, 0.01029058,\n",
       "        0.01119961, 0.00984573, 0.01025925, 0.01101724, 0.01066194,\n",
       "        0.01142314, 0.01046023, 0.01088517, 0.01101524, 0.01014855,\n",
       "        0.01382952, 0.00946699, 0.01382294, 0.01145752, 0.01230946,\n",
       "        0.01451662, 0.0112405 , 0.0141823 , 0.00991062, 0.01725945,\n",
       "        0.01911117, 0.0094124 , 0.0120395 , 0.00818533, 0.01099228,\n",
       "        0.01047215, 0.00911422, 0.00737221, 0.01044737, 0.0114465 ,\n",
       "        0.00703791, 0.00761131, 0.00768395, 0.00895203, 0.00710685,\n",
       "        0.01233352, 0.00776994, 0.00646441, 0.00676312, 0.00951902,\n",
       "        0.01012736, 0.01270906, 0.0093776 , 0.01227192, 0.01941985,\n",
       "        0.011088  , 0.0120331 , 0.01338007, 0.00844096, 0.00996742,\n",
       "        0.00847649, 0.00942919, 0.00822799, 0.00745618, 0.00806574,\n",
       "        0.00983715, 0.00823793, 0.00884723, 0.0083127 , 0.01127029,\n",
       "        0.00678105, 0.00921604, 0.0076344 , 0.00922076, 0.00864667,\n",
       "        0.00864394, 0.00808124, 0.00893797, 0.01029067, 0.00850731,\n",
       "        0.00792284, 0.01489289, 0.00863835], dtype=float32))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_intent(\"Please modify the data in range\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
