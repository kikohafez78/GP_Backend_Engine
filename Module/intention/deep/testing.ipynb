{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "05/14/2024 20:16:04 - INFO - numexpr.utils -   Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "05/14/2024 20:16:04 - INFO - numexpr.utils -   NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "# from bert_model_implementation_torch.model import BertModel\n",
    "from bert_model_implementation_torch.tokenization import  _is_control,_is_whitespace,_is_punctuation\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from keras.src.utils import to_categorical\n",
    "from torch.utils.data import DataLoader\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tApple\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "2\tis\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "3\tlooking\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "4\tat\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "5\tbuying\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "6\tU.K.\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "7\tstartup\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "8\tfor\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "9\t$1\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "10\tbillion\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import conllu\n",
    "\n",
    "# Define a sentence\n",
    "sentence = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
    "\n",
    "# Tokenize the sentence\n",
    "tokens = sentence.split()\n",
    "\n",
    "# Create a list of CoNLL Token objects\n",
    "conll_tokens = []\n",
    "for i, token in enumerate(tokens, start=1):\n",
    "    conll_tokens.append(conllu.Token(\n",
    "        id=i, form=token, lemma=\"_\", upos=\"_\", xpos=\"_\", feats=\"_\", head=\"_\", deprel=\"_\", deps=\"_\", misc=\"_\"\n",
    "    ))\n",
    "\n",
    "# Create a CoNLL object\n",
    "conll = conllu.TokenList(conll_tokens)\n",
    "\n",
    "# Print the CoNLL format\n",
    "print(conll.serialize())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox jumps over the lazy dog.\n"
     ]
    }
   ],
   "source": [
    "from conllu import parse\n",
    "\n",
    "# Sample sentence\n",
    "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# (Optional) Convert sentence to a spaCy doc (assuming you have spaCy installed)\n",
    "# doc = nlp(sentence)\n",
    "\n",
    "# Convert sentence (or spaCy doc) to CoNLL-U format (replace with your conversion logic)\n",
    "conll_data = sentence  # Replace with your conversion logic (e.g., using spaCy)\n",
    "\n",
    "# Parse the CoNLL-U data string\n",
    "parsed_data = parse(conll_data)\n",
    "\n",
    "# Access the tokens and their information in the parsed data object\n",
    "for token in parsed_data:\n",
    "  print(f\"ID: {token.id}, FORM: {token.form}, UPOS: {token.upos}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/Book1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>intent</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you update the sales figures in cells &lt;Cel...</td>\n",
       "      <td>Update cell range</td>\n",
       "      <td>entry and manipulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please modify the data in range &lt;Range&gt;</td>\n",
       "      <td>Update cell range</td>\n",
       "      <td>entry and manipulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I need to change the prices in cells &lt;Range&gt;</td>\n",
       "      <td>Update cell range</td>\n",
       "      <td>entry and manipulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Could you update the inventory levels from &lt;Ce...</td>\n",
       "      <td>Update cell range</td>\n",
       "      <td>entry and manipulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Please adjust the budget numbers in range &lt;Range&gt;</td>\n",
       "      <td>Update cell range</td>\n",
       "      <td>entry and manipulation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt             intent  \\\n",
       "0  Can you update the sales figures in cells <Cel...  Update cell range   \n",
       "1            Please modify the data in range <Range>  Update cell range   \n",
       "2       I need to change the prices in cells <Range>  Update cell range   \n",
       "3  Could you update the inventory levels from <Ce...  Update cell range   \n",
       "4  Please adjust the budget numbers in range <Range>  Update cell range   \n",
       "\n",
       "                  classes  \n",
       "0  entry and manipulation  \n",
       "1  entry and manipulation  \n",
       "2  entry and manipulation  \n",
       "3  entry and manipulation  \n",
       "4  entry and manipulation  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'max_len': 256,\n",
    "    'batch_size': 8,\n",
    "    'epochs': 10,\n",
    "    'lr':1e-05,\n",
    "    'out_first_layer': 768,\n",
    "    'dropout_rate': 0.1,\n",
    "    'model_dir':'bert-base-uncased',\n",
    "    'ckpt_path': './ckpts',\n",
    "    'ckpt_model_path': './experiments'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_list = data.intent.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class intent_dataset:\n",
    "    def __init__(self, df: pd.DataFrame, tokenizer: BertTokenizer, max_len: int):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.classes = data.intent.unique().tolist()\n",
    "        self.y = df['intent']\n",
    "        self.x = df['prompt']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        title = str(self.x[index])\n",
    "        title= ''.join(title.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            title,\n",
    "            None,\n",
    "            add_special_tokens = True,\n",
    "            return_attention_mask = True,\n",
    "            return_tensors = 'pt',\n",
    "            return_token_type_ids = True,\n",
    "            padding = 'max_length',\n",
    "            max_length = self.max_len,\n",
    "            truncation = True\n",
    "        )\n",
    "        # print(self.classes.index(self.y[index]))\n",
    "        target = self.classes.index(self.y[index])  # Get the class index\n",
    "        target_tensor = torch.zeros(len(self.classes),dtype= torch.float32)  # Initialize target tensor with zeros\n",
    "        target_tensor[target] = 1  # Set the corresponding index to 1\n",
    "        return {\n",
    "            'input_ids': inputs[\"input_ids\"].flatten(),\n",
    "            'token_type_ids': inputs['token_type_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'targets': target_tensor\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.sample(frac=0.9, random_state=200).reset_index(drop=True)\n",
    "val = data.drop(train.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(config[\"model_dir\"])\n",
    "train_dataset = intent_dataset(train, tokenizer, config[\"max_len\"])\n",
    "val_dataset = intent_dataset(val, tokenizer, config[\"max_len\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle = True,\n",
    "    batch_size = config[\"batch_size\"],\n",
    "    num_workers = 0\n",
    "    )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    shuffle = False,\n",
    "    batch_size = config[\"batch_size\"],\n",
    "    num_workers = 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[10]['targets']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader.dataset[0]['input_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckpt(ckpt_path, model, optimizer):\n",
    "    ckpt = torch.load(ckpt_path)\n",
    "    model.load_state_dict(ckpt['state_dict'])\n",
    "    optimizer.load_state_dict(ckpt['state_dict'])\n",
    "    valid_loss_min = ckpt['valid_loss_min']\n",
    "    return model, optimizer, ckpt['epoch'], valid_loss_min.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ckpt(state, is_best, ckpt_path, best_model_path):\n",
    "    f_path= ckpt_path\n",
    "    torch.save(state, f_path)\n",
    "    if is_best:\n",
    "        best_f_path = best_model_path\n",
    "        shutil.copyfile(f_path, best_f_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class intent_model(nn.Module):\n",
    "    def __init__(self, config: dict, intent_labels: list[str], dropout: float = 0.1):\n",
    "        super(intent_model,self).__init__()\n",
    "        self.config = config\n",
    "        self.intent_labels = intent_labels\n",
    "        self.dropout_rate = dropout\n",
    "        self.bert = BertModel.from_pretrained(self.config[\"model_dir\"])\n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "        self.layer_1 = nn.Linear(self.bert.config.hidden_size,self.config[\"out_first_layer\"])\n",
    "        self.activation_1 = nn.ReLU()\n",
    "        self.layer_2 = nn.Linear(self.config[\"out_first_layer\"], len(self.intent_labels))\n",
    "        \n",
    "    def forward(self, input_ids: torch.Tensor, token_type_ids: torch.Tensor, attention_mask: torch.Tensor):\n",
    "        output = self.bert(input_ids, token_type_ids, attention_mask)\n",
    "        output_dropout = self.dropout(output.pooler_output)\n",
    "        out_layer_1 = self.layer_1(output_dropout)\n",
    "        act_1 = self.activation_1(out_layer_1)\n",
    "        out_layer_2 = self.layer_2(act_1)\n",
    "        return out_layer_2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intent_model(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (layer_1): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (activation_1): ReLU()\n",
       "  (layer_2): Linear(in_features=768, out_features=93, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = intent_model(config, intent_list, 0.1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    targets = targets.float()\n",
    "    return nn.BCEWithLogitsLoss()(outputs, targets)\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = config[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, train_loader, val_loader, optimizer, ckpt_path, best_model_path):\n",
    "    valid_loss_min = np.Inf\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "        model.train()\n",
    "        for batch_index, batch in tqdm(enumerate(train_loader)):\n",
    "            input_ids = batch['input_ids'].to(device, dtype= torch.long)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device, dtype= torch.long)\n",
    "            token_type_ids = batch[\"token_type_ids\"].to(device, dtype= torch.long)\n",
    "            targets = batch[\"targets\"].to(device, dtype= torch.long)\n",
    "            outputs = model(input_ids, token_type_ids, attention_mask)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += (1/(batch_index + 1)) * (loss.item() - train_loss)\n",
    "        print(f\"epoch {epoch} ended with train loss of {train_loss}\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_index, batch in tqdm(enumerate(val_loader)):\n",
    "                input_ids = batch['input_ids'].to(device, dtype= torch.long)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device, dtype= torch.long)\n",
    "                token_type_ids = batch[\"token_type_ids\"].to(device, dtype= torch.long)\n",
    "                targets = batch[\"targets\"].to(device, dtype= torch.long)\n",
    "                outputs = model(input_ids, token_type_ids, attention_mask)\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                val_loss += (1/(batch_index + 1)) * (loss.item() - val_loss)\n",
    "        print(f\"epoch {epoch} ended with train loss of {valid_loss}\")\n",
    "        checkpoint = {\n",
    "            'epoch': epoch +1,\n",
    "            'valid_loss_min': val_loss,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "        save_ckpt(checkpoint, False, ckpt_path, best_model_path)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4648it [2:00:21,  1.55s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train \u001b[38;5;241m=\u001b[39m train(model, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m], train_loader, val_loader, optimizer, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mckpt_path\u001b[39m\u001b[38;5;124m\"\u001b[39m], config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mckpt_model_path\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[1;32mIn[19], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, epochs, train_loader, val_loader, optimizer, ckpt_path, best_model_path)\u001b[0m\n\u001b[0;32m     16\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 18\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(batch_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m (loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m-\u001b[39m train_loss)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ended with train loss of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train = train(model, config[\"epochs\"], train_loader, val_loader, optimizer, config[\"ckpt_path\"], config[\"ckpt_model_path\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
